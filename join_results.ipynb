{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "data_dir = '../chunwei-data'\n",
    "output_dir = '../chunwei-data/predictions'\n",
    "num_labels = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_edges = np.linspace(0, 512, num_labels + 1)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, 'split', f'seed{seed}.json'), 'r') as fin:\n",
    "    split = json.load(fin)\n",
    "test_ids = set(split['test'])\n",
    "\n",
    "with open(os.path.join(data_dir, 'all_layers_1k.json'), 'r') as fin:\n",
    "    records = json.load(fin)['records'][1:]\n",
    "\n",
    "test_records = [x for x in records if x['record_id'] in test_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = list()\n",
    "for r in test_records:\n",
    "    raw_prompt = r['output']\n",
    "    pstart = raw_prompt.index('Below is an instruction')\n",
    "    pend = raw_prompt.index('### Response:')\n",
    "    prompt = raw_prompt[pstart:pend] + '### Response:'\n",
    "    output.append({\n",
    "        \"id\": r['record_id'],\n",
    "        \"prompt\": prompt,\n",
    "        \"groundtruth\": r['iteration_count']\n",
    "    })\n",
    "\n",
    "ids = [x['id'] for x in output]\n",
    "sorted_idx = np.argsort(ids)\n",
    "output = [output[i] for i in sorted_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3681af4e8ed4c1e98e6fb319156edfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def convert_logit_to_pred(logits, bin_edges):\n",
    "    exp_x = np.exp(logits - np.amax(logits))\n",
    "    proba = exp_x / np.sum(exp_x)\n",
    "    return np.sum([p * b for p, b in zip(proba, bin_edges)])\n",
    "\n",
    "\n",
    "for layer_idx in tqdm(range(32)):\n",
    "\n",
    "    pred_by_id = dict()\n",
    "\n",
    "    cached_pred_path = os.path.join(output_dir, f'L{layer_idx}_class{num_labels}_seed{seed}.pkl')\n",
    "    if os.path.isfile(cached_pred_path):\n",
    "        with open(cached_pred_path, 'rb') as fout:\n",
    "            pred_raw = pkl.load(fout)\n",
    "        \n",
    "        pred = list()\n",
    "        for raw in pred_raw:\n",
    "            pred.append({\n",
    "                'id': raw['id'],\n",
    "                'remaining_steps': raw['remaining_steps'],\n",
    "                'pred': convert_logit_to_pred(raw['pred'], bin_edges)\n",
    "            })\n",
    "        \n",
    "        pred = pd.DataFrame(pred)\n",
    "        grb_id = pred.groupby(by='id')\n",
    "        \n",
    "        for id, sub_df in grb_id:\n",
    "            rs, ps = sub_df.remaining_steps.values, sub_df.pred.values\n",
    "            sorted_idx = np.argsort(rs)[::-1]\n",
    "            rs = rs[sorted_idx]\n",
    "            ps = ps[sorted_idx]\n",
    "\n",
    "            pred_by_id[id] = ps.tolist()\n",
    "        \n",
    "        for rec in output:\n",
    "            pred_vec = pred_by_id[rec['id']]\n",
    "            rec[f'pred_refined_L{layer_idx}'] = pred_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'eval/alpaca-by-layer-seed{seed}-class{num_labels}.json', 'w') as fout:\n",
    "    json.dump(output, fout, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "schedule",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
